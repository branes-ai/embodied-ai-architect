# Drone Perception Pipeline

A progressive perception pipeline for drone-based object detection, tracking, 3D reasoning, and situational awareness.

ğŸ“‹ **[CHANGELOG](CHANGELOG.md)** | ğŸ“ **[Latest Session Log](../../docs/sessions/2025-11-21-drone-perception-phase3-tracking-improvements.md)**

## Quick Start

### Installation

```bash
cd prototypes/drone_perception
pip install -r requirements.txt
```

### Run Full Pipeline (âœ… Working!)

```bash
# Basic usage with webcam (monocular)
python examples/full_pipeline.py --video 0

# Or with a video file
python examples/full_pipeline.py --video your_video.mp4

# Advanced: GPU + specific classes + save output
python examples/full_pipeline.py \
    --video test.mp4 \
    --device cuda \
    --model s \
    --classes 0 2 7 \
    --save-video output.mp4

# Stereo mode with RealSense D435 (Phase 2)
python examples/full_pipeline.py --stereo --stereo-backend realsense

# Stereo mode with OAK-D
python examples/full_pipeline.py --stereo --stereo-backend oakd

# Dedicated stereo pipeline example
python examples/stereo_pipeline.py --backend realsense --model s

# 3D Reasoning Pipeline (Phase 3) - Trajectory prediction, collision detection, behavior analysis
python examples/reasoning_pipeline.py --camera 0 --model s --prediction-horizon 3.0
```

**See [QUICKSTART.md](QUICKSTART.md) for detailed instructions!**

**NEW: [Phase 3 Reasoning Documentation](docs/phase3_reasoning.md)** - Trajectory prediction, collision detection, spatial analysis, and behavior classification

## Progressive Sensor Support

This pipeline is designed to work with three levels of sensor complexity:

### Level 1: Monocular Camera
- **Input**: Video file or webcam
- **Depth**: Estimated via heuristics or MiDaS
- **Use Case**: Development, testing, recorded data
- **Status**: ğŸš§ In Progress

### Level 2: Stereo Camera
- **Input**: RealSense D435, OAK-D
- **Depth**: Stereo depth map
- **Use Case**: Metric tracking, velocity estimation
- **Status**: âœ… Complete

### Level 3: LiDAR + Camera
- **Input**: Livox/Velodyne + Camera
- **Depth**: 3D point cloud
- **Use Case**: Industrial deployment, high accuracy
- **Status**: ğŸ“‹ Planned

## Architecture

See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed design.

```
Camera â†’ Detection â†’ Tracking â†’ Scene Graph â†’ Reasoning â†’ Visualization
         (YOLOv8)   (ByteTrack)  (Kalman)      (Phase 3)   (3D Plot)
                                                   â†“
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  - Trajectory Prediction    â”‚
                                    â”‚  - Collision Detection      â”‚
                                    â”‚  - Spatial Analysis         â”‚
                                    â”‚  - Behavior Classification  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features

### Perception (Phase 1 & 2)
- âœ… **Object detection** with YOLOv8 (nano to xlarge models)
- âœ… **Multi-object tracking** with ByteTrack (ID persistence, re-identification)
- âœ… **3D scene graph** with position/velocity/acceleration estimation
- âœ… **Kalman filtering** for smooth state estimation (9D state per object)
- âœ… **Real-time 3D visualization** with matplotlib (position, velocity, trajectories)
- âœ… **Sensor abstraction** ready for monocular â†’ stereo â†’ LiDAR progression

### 3D Reasoning & Planning (Phase 3) - NEW!
- âœ… **Trajectory prediction** - Constant velocity, acceleration, and physics-based models
- âœ… **Collision detection** - Time-to-collision with 5-level risk assessment
- âœ… **Spatial analysis** - Relative positioning, proximity detection, clustering
- âœ… **Behavior classification** - Stationary, moving, turning, accelerating, approaching
- âœ… **Real-time visualization** - Predicted trajectories with color-coded risk levels

### Coming Soon
- ğŸ“‹ HDF5 recording for replay
- ğŸ“‹ LiDAR sensor support

## Project Structure

```
drone_perception/
â”œâ”€â”€ sensors/                    # Camera abstractions
â”‚   â”œâ”€â”€ base.py                # BaseSensor interface
â”‚   â”œâ”€â”€ monocular.py           # Video/webcam
â”‚   â”œâ”€â”€ stereo.py              # RealSense/OAK-D
â”‚   â”œâ”€â”€ wide_angle.py          # Fisheye/wide-angle cameras
â”‚   â””â”€â”€ lidar.py               # LiDAR fusion
â”œâ”€â”€ detection/                  # Object detection
â”‚   â””â”€â”€ yolo.py                # YOLOv8 wrapper
â”œâ”€â”€ tracking/                   # Object tracking
â”‚   â”œâ”€â”€ bytetrack.py           # ByteTrack implementation
â”‚   â””â”€â”€ kalman_filter.py       # Kalman box filter
â”œâ”€â”€ scene_graph/                # World state management
â”‚   â””â”€â”€ manager.py             # 3D scene graph with Kalman filtering
â”œâ”€â”€ reasoning/                  # 3D reasoning & planning (Phase 3)
â”‚   â”œâ”€â”€ trajectory_predictor.py   # Future path prediction
â”‚   â”œâ”€â”€ collision_detector.py     # Risk assessment & avoidance
â”‚   â”œâ”€â”€ spatial_analyzer.py       # Relative positioning & proximity
â”‚   â””â”€â”€ behavior_classifier.py    # Motion pattern classification
â”œâ”€â”€ visualization/              # Rendering
â”‚   â”œâ”€â”€ live_view.py           # Real-time 3D plot
â”‚   â””â”€â”€ replay.py              # Playback from HDF5
â”œâ”€â”€ examples/                   # Usage examples
â”‚   â”œâ”€â”€ full_pipeline.py       # Complete monocular/stereo pipeline
â”‚   â”œâ”€â”€ stereo_pipeline.py     # Dedicated stereo example
â”‚   â””â”€â”€ reasoning_pipeline.py  # 3D reasoning demo (Phase 3)
â”œâ”€â”€ docs/                       # Documentation
â”‚   â””â”€â”€ phase3_reasoning.md    # Phase 3 guide
â””â”€â”€ CHANGELOG.md               # Version history
```

**Note:** Development session logs are maintained in `../../docs/sessions/`

## Development Status

### âœ… Phase 1: Monocular Pipeline (COMPLETE)
- [x] Project structure and architecture
- [x] Sensor abstraction layer (monocular camera)
- [x] YOLOv8 detection integration
- [x] ByteTrack multi-object tracking
- [x] 3D scene graph with Kalman filtering
- [x] Real-time 3D visualization
- [x] Full end-to-end example

### âœ… Phase 2: Multi-Sensor Support (COMPLETE)
- [x] RealSense D435 integration
- [x] OAK-D support
- [x] Wide-angle/fisheye camera support
- [x] Depth Any Camera (DAC) integration
- [x] Depth map fusion
- [x] Metric accuracy validation
- [x] Stereo pipeline example
- [x] Updated full_pipeline.py with --stereo flag

### âœ… Phase 3: 3D Reasoning & Planning (COMPLETE - Nov 2025)
- [x] Trajectory prediction (constant velocity, acceleration, physics-based)
- [x] Collision detection with risk assessment
- [x] Spatial analysis (relative positioning, proximity)
- [x] Behavior classification (stationary, moving, turning, etc.)
- [x] Real-time reasoning pipeline example
- [x] Comprehensive documentation (docs/phase3_reasoning.md)
- [x] Performance optimizations (frame skipping, reduced resolution)
- [x] Enhanced tracking (improved re-identification, object pruning)

### ğŸ“‹ Phase 4: Recording & Replay
- [ ] HDF5 data recording
- [ ] Replay viewer with timeline
- [ ] Export to common formats

### ğŸ“‹ Phase 5: Production Ready
- [ ] LiDAR sensor support (Livox/Velodyne)
- [ ] Multi-rate framework integration
- [ ] Performance optimization (30+ FPS on edge devices)
- [ ] Unit tests and CI/CD
- [ ] Docker deployment

## References

- Research: `../../docs/research/drone-pipeline.md`
- Multi-Rate Framework: `../multi_rate_framework/`
- ByteTrack: https://github.com/ifzhang/ByteTrack
- YOLOv8: https://github.com/ultralytics/ultralytics
